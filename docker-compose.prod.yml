services:
  caddy:
    image: caddy:2-alpine
    container_name: scale-caddy
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    environment:
      - ACME_EMAIL=${ACME_EMAIL}
      - FRONTEND_DOMAIN=${FRONTEND_DOMAIN}
      - BACKEND_DOMAIN=${BACKEND_DOMAIN}
      - MONITORING_DOMAIN=${MONITORING_DOMAIN}
      - MONITORING_USER=admin
      - MONITORING_HASH=${GRAFANA_ADMIN_PASSWORD}
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy_data:/data
      - caddy_config:/config
    networks:
      - scale-network

  backend:
    image: ghcr.io/${GITHUB_REPOSITORY_OWNER}/scale-app-backend:0.0.1
    container_name: scale-backend
    restart: unless-stopped
    env_file:
      - .env.backend
    depends_on:
      - timescaledb
      - redis
      - mqtt
    networks:
      - scale-network
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3000/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  frontend:
    image: ghcr.io/${GITHUB_REPOSITORY_OWNER}/scale-app-frontend:0.0.1
    container_name: scale-frontend
    restart: unless-stopped
    env_file:
      - .env.frontend
    depends_on:
      - backend
    networks:
      - scale-network
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3000', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  timescaledb:
    image: timescale/timescaledb-ha:pg18-all
    container_name: scale-db
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: ${DB_NAME}
    volumes:
      - scale_db_data:/var/lib/postgresql/data
    networks:
      - scale-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER} -d ${DB_NAME}"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:alpine
    container_name: scale-cache
    restart: unless-stopped
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - scale_redis_data:/data
    networks:
      - scale-network
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  mqtt:
    image: eclipse-mosquitto:2.0.22
    container_name: scale-mqtt
    restart: unless-stopped
    ports:
      - "1883:1883"
      - "9001:9001"
    volumes:
      - ./mosquitto/config/mosquitto.prod.conf:/mosquitto/config/mosquitto.conf:ro
      - ./mosquitto/config/password.txt:/mosquitto/config/password.txt:ro
      - scale_mqtt_data:/mosquitto/data
      - scale_mqtt_log:/mosquitto/log
    networks:
      - scale-network
    healthcheck:
      test: ["CMD", "mosquitto_sub", "-t", "$$SYS/#", "-C", "1", "-i", "healthcheck", "-W", "3"]
      interval: 30s
      timeout: 10s
      retries: 3

  prometheus:
    image: prom/prometheus:latest
    container_name: scale-prometheus
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.retention.time=30d'
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    networks:
      - scale-network

  grafana:
    image: grafana/grafana:latest
    container_name: scale-grafana
    restart: unless-stopped
    environment:
      - GF_SERVER_ROOT_URL=https://${MONITORING_DOMAIN}/grafana
      - GF_SERVER_SERVE_FROM_SUB_PATH=true
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
    networks:
      - scale-network

  loki:
    image: grafana/loki:latest
    container_name: scale-loki
    restart: unless-stopped
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - ./monitoring/loki/loki-config.yml:/etc/loki/local-config.yaml:ro
      - loki_data:/loki
    networks:
      - scale-network

  promtail:
    image: grafana/promtail:latest
    container_name: scale-promtail
    restart: unless-stopped
    volumes:
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - ./monitoring/promtail/promtail-config.yml:/etc/promtail/config.yml:ro
    command: -config.file=/etc/promtail/config.yml
    networks:
      - scale-network

  node-exporter:
    image: prom/node-exporter:latest
    container_name: scale-node-exporter
    restart: unless-stopped
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
    networks:
      - scale-network

  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    container_name: scale-postgres-exporter
    restart: unless-stopped
    environment:
      DATA_SOURCE_NAME: "postgresql://${DB_USER}:${DB_PASSWORD}@timescaledb:5432/${DB_NAME}?sslmode=disable"
    networks:
      - scale-network

volumes:
  scale_db_data:
  scale_redis_data:
  scale_mqtt_data:
  scale_mqtt_log:
  prometheus_data:
  grafana_data:
  loki_data:
  caddy_data:
  caddy_config:

networks:
  scale-network:
    driver: bridge
